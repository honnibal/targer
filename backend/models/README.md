Download the pretrained models and unpack them into this directory. Afterwards there should be 6 *.h5 files in this folder.

* ES.h5 - ES dataset with "shrinked" fasttext embeddings: https://drive.google.com/open?id=1jp1VrEBrH-bHo28VvzCDc4U4hX1OwoAc
* WD.h5 - WD dataset with "shrinked" fasttext embeddings: https://drive.google.com/open?id=1IOocdCQvwPVzRFlYfiznCv_iQIKr1RTp
* ES_dep.h5 - ES dataset with full Dependency Based embeddings by [1]: https://goo.gl/gcF8VP
* WD_dep.h5 - WD dataset with full  Dependency Based embeddings by [1]:  https://goo.gl/82iWwA
* COMBO.h5 - COMBO dataset trained on all datasets combined: https://drive.google.com/open?id=18AAYTvNEdZgCZvklu7PDMNSYCvladxh2
* IBM.h5 - Model trained on IBM data fasttext embedding: https://drive.google.com/open?id=19ciQydNXRM5VmtP5z9j6hh8ukpOyg8TD
